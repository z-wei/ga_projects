{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Q1</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('../Samson/salary_df_car_fut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of text and numeric column names\n",
    "textcolnames = ['Company', 'Title', 'Address', 'Emp_type', 'Seniority', 'Industry', 'Responsibility', 'Requirements']\n",
    "numericcolnames = ['Salary_avg']\n",
    "\n",
    "#drop column\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "#clean 'Salary' column\n",
    "df = df[df['Salary'] != 'NONE']\n",
    "df['Salary_lower'] = df['Salary'].apply(lambda x: x.replace('$','').replace(',','').split('to')[0]).astype('float')\n",
    "df['Salary_higher'] = df['Salary'].apply(lambda x: x.replace('$','').replace(',','').split('to')[1]).astype('float')\n",
    "df['Salary_avg'] = (df['Salary_lower'] + df['Salary_higher']) /2\n",
    "df['Salary_avg'] = df['Salary_avg'].apply(lambda x: round(x/12,1) if x > 30000 else x)\n",
    "df.drop(['Salary', 'Salary_lower', 'Salary_higher'], axis=1, inplace=True)\n",
    "\n",
    "#clean text columns\n",
    "df[textcolnames] = df[textcolnames].apply(lambda x: x.str.lower())\n",
    "df[textcolnames] = df[textcolnames].apply(lambda x: x.str.replace('[^\\w\\s]',' '))\n",
    "\n",
    "#function to combine text columns for CountVec to process\n",
    "def combine_text_columns(data_frame, to_drop=numericcolnames):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING TARGET VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of high salaried rows: 211\n",
      "number of low salaried rows: 1091\n"
     ]
    }
   ],
   "source": [
    "#create predictor\n",
    "X = combine_text_columns(df)\n",
    "\n",
    "#create target variable\n",
    "df['Salary_binary'] = df['Salary_avg'].apply(lambda x: 1 if x > 10000 else 0)\n",
    "print('number of high salaried rows: {}'.format(len(df[df['Salary_binary']  == 1])))\n",
    "print('number of low salaried rows: {}'.format(len(df[df['Salary_binary']  == 0])))\n",
    "\n",
    "#create new dataframe with predictors and target\n",
    "df2 = pd.DataFrame(X,columns=['all_text'])\n",
    "df2['over10k'] = df['Salary_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest\n",
      "0.8314176245210728\n",
      "========================================\n",
      "logistic regression\n",
      "0.8390804597701149\n",
      "========================================\n",
      "base line\n",
      "0    0.837942\n",
      "1    0.162058\n",
      "Name: over10k, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df2['over10k']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, \n",
    "                                                    test_size=0.2, stratify=df2['over10k'])\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#add to stopwords list\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwordslist = stopwords.words('english')\n",
    "stopwordslist.extend(['requirements', 'roles', 'responsibilities', 'qualifications', \n",
    "                    'responsibilitiesresponsibilities', 'scope','requirementseducation',\n",
    "                     'required', 'na', 'n a'])\n",
    "\n",
    "\n",
    "#randomforestclassifier (an ensemble method that using averaging)\n",
    "forest = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=stopwordslist)),\n",
    "    ('clf', RandomForestClassifier())\n",
    "                ])\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "print('randomforest')\n",
    "print(forest.score(X_test, y_test))\n",
    "print('='*40)\n",
    "\n",
    "#logisticregression\n",
    "logistic = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=stopwordslist)),\n",
    "    ('clf', LogisticRegression())\n",
    "                ])\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "print('logistic regression')\n",
    "print(logistic.score(X_test, y_test))\n",
    "print('='*40)\n",
    "print('base line')\n",
    "print(y.value_counts() / len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_impt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.012041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk</th>\n",
       "      <td>0.009351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>0.007561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prioritisation</th>\n",
       "      <td>0.007349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftl</th>\n",
       "      <td>0.006422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior</th>\n",
       "      <td>0.006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrange</th>\n",
       "      <td>0.005928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy</th>\n",
       "      <td>0.005577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>0.005102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thus</th>\n",
       "      <td>0.005008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wealth</th>\n",
       "      <td>0.004889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0.004805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approximately</th>\n",
       "      <td>0.004584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>including</th>\n",
       "      <td>0.004471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>believe</th>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click</th>\n",
       "      <td>0.004263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>practice</th>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>0.003976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics</th>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature_impt\n",
       "lead                0.012041\n",
       "risk                0.009351\n",
       "services            0.007561\n",
       "prioritisation      0.007349\n",
       "ftl                 0.006422\n",
       "senior              0.006029\n",
       "arrange             0.005928\n",
       "strategy            0.005577\n",
       "drive               0.005102\n",
       "thus                0.005008\n",
       "wealth              0.004889\n",
       "cloud               0.004805\n",
       "approximately       0.004584\n",
       "scoring             0.004473\n",
       "including           0.004471\n",
       "believe             0.004386\n",
       "click               0.004263\n",
       "practice            0.003998\n",
       "years               0.003976\n",
       "analytics           0.003942"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize model\n",
    "forest = RandomForestClassifier()\n",
    "cv = CountVectorizer(stop_words=stopwordslist)\n",
    "X_1 = cv.fit_transform(X)\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1.toarray(), df2['over10k'], random_state=1, test_size=0.2, stratify=df2['over10k'])\n",
    "forest.fit(X_train, y_train)\n",
    "forest.score(X_test, y_test)\n",
    "\n",
    "#feature importances\n",
    "f_impt = forest.feature_importances_\n",
    "idx = cv.get_feature_names()\n",
    "df_forestfeatures = pd.DataFrame(f_impt,  index=idx, columns=['feature_impt'])\n",
    "df_forestfeatures.sort_values('feature_impt', ascending=False, inplace=True) #how do I track down these 20 words? \n",
    "df_forestfeatures[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead\n",
      "list is title\n",
      "====================\n",
      "risk\n",
      "list is company\n",
      "====================\n",
      "services\n",
      "list is company\n",
      "====================\n",
      "prioritisation\n",
      "list is responsibility\n",
      "====================\n",
      "ftl\n",
      "list is responsibility\n",
      "====================\n",
      "senior\n",
      "list is title\n",
      "====================\n",
      "arrange\n",
      "list is responsibility\n",
      "====================\n",
      "strategy\n",
      "list is company\n",
      "====================\n",
      "drive\n",
      "list is address\n",
      "====================\n",
      "thus\n",
      "list is responsibility\n",
      "====================\n",
      "wealth\n",
      "list is title\n",
      "====================\n",
      "cloud\n",
      "list is title\n",
      "====================\n",
      "approximately\n",
      "list is responsibility\n",
      "====================\n",
      "scoring\n",
      "list is title\n",
      "====================\n",
      "including\n",
      "list is responsibility\n",
      "====================\n",
      "believe\n",
      "list is responsibility\n",
      "====================\n",
      "click\n",
      "list is responsibility\n",
      "====================\n",
      "practice\n",
      "list is title\n",
      "====================\n",
      "years\n",
      "list is responsibility\n",
      "====================\n",
      "analytics\n",
      "list is company\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#function to convert each column feature into a list of words\n",
    "def featurewordlist(df, col_name):\n",
    "    \n",
    "    sentences = []\n",
    "    for x in df[col_name]:\n",
    "        sentences.append(x)\n",
    "\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        words.extend(sentence.split())\n",
    "\n",
    "    return list(set(words))\n",
    "\n",
    "#creating the list of words for each feature\n",
    "company = featurewordlist(df, 'Company')\n",
    "title = featurewordlist(df, 'Title')\n",
    "address = featurewordlist(df, 'Address')\n",
    "emp_type = featurewordlist(df, 'Emp_type')\n",
    "seniority = featurewordlist(df, 'Seniority')\n",
    "industry = featurewordlist(df, 'Industry')\n",
    "responsibility = featurewordlist(df, 'Responsibility')\n",
    "requirements =featurewordlist(df, 'Requirements')\n",
    "\n",
    "#creating empty lists to do a word count \n",
    "company_count = [] \n",
    "title_count = []\n",
    "address_count = []\n",
    "emp_type_count = []\n",
    "seniority_count = []\n",
    "industry_count = []\n",
    "responsibility_count = []\n",
    "requirements_count = []\n",
    "\n",
    "countdict = {'company': company_count, \n",
    "             'title': title_count, \n",
    "             'address': address_count, \n",
    "             'emp_type': emp_type_count, \n",
    "             'seniority': seniority_count, \n",
    "             'industry': industry_count, \n",
    "             'responsibility': responsibility_count, \n",
    "             'requirements': requirements_count}\n",
    "\n",
    "#extract only the top 20 word features\n",
    "top20feats = df_forestfeatures['feature_impt'][:20].index\n",
    "\n",
    "#loop through to print word feature and the feature column it belongs to\n",
    "for x in top20feats:\n",
    "    print (x)\n",
    "    if x in company:\n",
    "        print ('list is company')\n",
    "        company_count.append(x)\n",
    "    elif x in title:\n",
    "        print ('list is title')\n",
    "        title_count.append(x)\n",
    "    elif x in address:\n",
    "        print ('list is address')\n",
    "        address_count.append(x)\n",
    "    elif x in emp_type:\n",
    "        print ('list is emp_type')\n",
    "        emp_type_count.append(x)\n",
    "    elif x in seniority:\n",
    "        print ('list is seniority')\n",
    "        seniority_count.append(x)\n",
    "    elif x in industry:\n",
    "        print ('list is industry')\n",
    "        industry_count.append(x)\n",
    "    elif x in responsibility:\n",
    "        print ('list is responsibility')\n",
    "        responsibility_count.append(x)\n",
    "    elif x in requirements:\n",
    "        print ('list is requirements')\n",
    "        requirements_count.append(x)\n",
    "    else:\n",
    "        print ('word not in list, how can that be?')\n",
    "    print ('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPANY: 4\n",
      "TITLE: 6\n",
      "ADDRESS: 1\n",
      "EMP_TYPE: 0\n",
      "SENIORITY: 0\n",
      "INDUSTRY: 0\n",
      "RESPONSIBILITY: 9\n",
      "REQUIREMENTS: 0\n"
     ]
    }
   ],
   "source": [
    "for key, value in countdict.items():\n",
    "    #print value\n",
    "    print(key.upper() + ':', len([item for item in value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8544061302681992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_impt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>senior management</th>\n",
       "      <td>0.013077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business product</th>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grow committed</th>\n",
       "      <td>0.005158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geographies</th>\n",
       "      <td>0.005154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banking</th>\n",
       "      <td>0.005053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance reporting</th>\n",
       "      <td>0.004571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assigned time</th>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effectiveness</th>\n",
       "      <td>0.004507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquidity risk</th>\n",
       "      <td>0.004244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy environments</th>\n",
       "      <td>0.004244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field role</th>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product adwords</th>\n",
       "      <td>0.004162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business ability</th>\n",
       "      <td>0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring boot</th>\n",
       "      <td>0.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumer base</th>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0.003941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provoking</th>\n",
       "      <td>0.003877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rochester</th>\n",
       "      <td>0.003768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continue grow</th>\n",
       "      <td>0.003733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python development</th>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_impt\n",
       "senior management          0.013077\n",
       "business product           0.005581\n",
       "grow committed             0.005158\n",
       "geographies                0.005154\n",
       "banking                    0.005053\n",
       "performance reporting      0.004571\n",
       "assigned time              0.004555\n",
       "effectiveness              0.004507\n",
       "liquidity risk             0.004244\n",
       "energy environments        0.004244\n",
       "field role                 0.004200\n",
       "product adwords            0.004162\n",
       "business ability           0.004135\n",
       "spring boot                0.004053\n",
       "consumer base              0.003945\n",
       "support                    0.003941\n",
       "provoking                  0.003877\n",
       "rochester                  0.003768\n",
       "continue grow              0.003733\n",
       "python development         0.003666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize model\n",
    "forest = RandomForestClassifier()\n",
    "cv = CountVectorizer(stop_words=stopwordslist, ngram_range=(1,2))\n",
    "X = cv.fit_transform(X).toarray()\n",
    "y = df2['over10k']\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify=df2['over10k'])\n",
    "forest.fit(X_train, y_train)\n",
    "print (forest.score(X_test, y_test))\n",
    "\n",
    "#feature importances\n",
    "f_impt = forest.feature_importances_\n",
    "idx = cv.get_feature_names()\n",
    "df_forestfeatures = pd.DataFrame(f_impt,  index=idx, columns=['feature_impt'])\n",
    "df_forestfeatures.sort_values('feature_impt', ascending=False, inplace=True) #how do I track down these 20 words? \n",
    "df_forestfeatures[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOMIZED GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True, total=  52.1s\n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True, total=  54.7s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True, total=  51.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  1.1min remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total= 1.2min\n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=  44.6s\n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=  45.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.842911877394636"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [20, 40, 60, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 1000, 1800]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 2, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "rf_random.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Score:\t 0.8387143952812247\n",
      "Bagging Score:\t 0.8387179428523801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator = rf, max_samples=0.5, max_features=0.5)\n",
    "\n",
    "print (\"RF Score:\\t\", cross_val_score(rf, X, y, cv=3, n_jobs=-1).mean())\n",
    "print (\"Bagging Score:\\t\", cross_val_score(bagging, X, y, cv=3, n_jobs=-1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Q2</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 unique values in Seniority columns.\n",
      "19.3125 times less unique values than Title column\n"
     ]
    }
   ],
   "source": [
    "#deciding which column to use as the target variable\n",
    "df = df.drop('Salary_binary', axis=1)\n",
    "print('{} unique values in Seniority columns.'.format(len(df['Seniority'].value_counts())))\n",
    "print('{} times less unique values than Title column'.format(927/float(48)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "filtered = df.groupby('Seniority')['Seniority'].filter(lambda x: len(x) > 3)\n",
    "df2 = df[df['Seniority'].isin(filtered)]\n",
    "\n",
    "#data cleaning on the column of interest\n",
    "df['Seniority'] = df['Seniority'].apply(lambda x: x.strip().replace('fresh', 'entry').replace('level', '').replace('manager', 'management'))\n",
    "df['Seniority'] = df['Seniority'].apply(lambda x: x.split())\n",
    "\n",
    "#function to remove duplicates\n",
    "def unique_list(listwithduplicates):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in listwithduplicates if x not in ulist]\n",
    "    return ulist\n",
    "\n",
    "df['Seniority'] = df['Seniority'].apply(unique_list)\n",
    "df['Seniority'] = df['Seniority'].apply(lambda x: ' '.join(x).replace('management', 'executive').split())\n",
    "df['Seniority'] = df['Seniority'].apply(unique_list)\n",
    "df['Seniority'] = df['Seniority'].apply(lambda x: sorted(x))\n",
    "df['Seniority'] = df['Seniority'].apply(lambda x: ' '.join(x))\n",
    "df = df[df['Seniority'] != 'none']\n",
    "\n",
    "#create target column\n",
    "df['non_exec'] = df['Seniority'].apply(lambda x: 0 if 'exec' in x else 1)\n",
    "\n",
    "#grouping my columns into numeric or text\n",
    "numericcolnames = ['Salary_avg']\n",
    "textcolnames.remove('Seniority')\n",
    "targetcolname = ['non_exec']\n",
    "nontargetcolnames = numericcolnames + textcolnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST:\n",
      "0.7246376811594203\n",
      "====================\n",
      "LOGISTIC REGRESSION:\n",
      "0.6763285024154589\n",
      "====================\n",
      "base line\n",
      "0.0    0.738372\n",
      "1.0    0.261628\n",
      "Name: non_exec, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats_impt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Salary_avg</th>\n",
       "      <td>0.042059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roi</th>\n",
       "      <td>0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travelling</th>\n",
       "      <td>0.004504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.003839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen</th>\n",
       "      <td>0.003753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.003547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conduct</th>\n",
       "      <td>0.003456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parallel</th>\n",
       "      <td>0.003428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing</th>\n",
       "      <td>0.003341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postgres</th>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commercially</th>\n",
       "      <td>0.003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chips</th>\n",
       "      <td>0.003223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development</th>\n",
       "      <td>0.003201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jee</th>\n",
       "      <td>0.003036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follows</th>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>0.002952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.002890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feats_impt\n",
       "Salary_avg      0.042059\n",
       "roi             0.005297\n",
       "functional      0.004700\n",
       "travelling      0.004504\n",
       "europe          0.004004\n",
       "state           0.003839\n",
       "screen          0.003753\n",
       "data            0.003547\n",
       "11              0.003467\n",
       "conduct         0.003456\n",
       "parallel        0.003428\n",
       "playing         0.003341\n",
       "postgres        0.003324\n",
       "commercially    0.003253\n",
       "chips           0.003223\n",
       "development     0.003201\n",
       "jee             0.003036\n",
       "follows         0.003026\n",
       "game            0.002952\n",
       "realization     0.002890"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating my predictor and target columns \n",
    "cv = CountVectorizer(stop_words=stopwordslist)\n",
    "cv.fit(combine_text_columns(df[textcolnames]))\n",
    "\n",
    "text = pd.DataFrame(cv.fit_transform(combine_text_columns(df[textcolnames])).toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "text['Salary_avg'] = df[numericcolnames]\n",
    "text['non_exec'] = df[targetcolname]\n",
    "text = text[np.isfinite(text['Salary_avg'])]\n",
    "\n",
    "X = text.iloc[:,:-1]\n",
    "y = text.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=text.iloc[:,-1])\n",
    "\n",
    "#random forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print('RANDOM FOREST:')\n",
    "print(rf.score(X_test, y_test))\n",
    "\n",
    "#logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('='*20)\n",
    "print('LOGISTIC REGRESSION:')\n",
    "print(lr.score(X_test, y_test))\n",
    "print('='*20)\n",
    "print('base line')\n",
    "print(y.value_counts() / len(y))\n",
    "\n",
    "\n",
    "\n",
    "#input top 20 features into a dataframe\n",
    "featsimpt = pd.DataFrame(rf.feature_importances_ , index=X_train.columns, columns=['feats_impt'])\n",
    "featsimpt.sort_values('feats_impt', ascending=False, inplace=True)\n",
    "feats20 = featsimpt[:20]\n",
    "feats20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi\n",
      "appears in feature responsibility\n",
      "====================\n",
      "functional\n",
      "appears in feature title\n",
      "====================\n",
      "travelling\n",
      "appears in feature responsibility\n",
      "====================\n",
      "europe\n",
      "appears in feature company\n",
      "====================\n",
      "state\n",
      "appears in feature company\n",
      "====================\n",
      "screen\n",
      "appears in feature responsibility\n",
      "====================\n",
      "data\n",
      "appears in feature company\n",
      "====================\n",
      "11\n",
      "appears in feature title\n",
      "====================\n",
      "conduct\n",
      "appears in feature title\n",
      "====================\n",
      "parallel\n",
      "appears in feature responsibility\n",
      "====================\n",
      "playing\n",
      "appears in feature responsibility\n",
      "====================\n",
      "postgres\n",
      "appears in feature responsibility\n",
      "====================\n",
      "commercially\n",
      "appears in feature responsibility\n",
      "====================\n",
      "chips\n",
      "appears in feature responsibility\n",
      "====================\n",
      "development\n",
      "appears in feature title\n",
      "====================\n",
      "jee\n",
      "appears in feature requirements\n",
      "====================\n",
      "follows\n",
      "appears in feature responsibility\n",
      "====================\n",
      "game\n",
      "appears in feature responsibility\n",
      "====================\n",
      "realization\n",
      "appears in feature responsibility\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "company_count = [] \n",
    "title_count = []\n",
    "address_count = []\n",
    "emp_type_count = []\n",
    "seniority_count = []\n",
    "industry_count = []\n",
    "responsibility_count = []\n",
    "requirements_count = []\n",
    "\n",
    "countdict = {'company': company_count, \n",
    "             'title': title_count, \n",
    "             'address': address_count, \n",
    "             'emp_type': emp_type_count, \n",
    "             'seniority': seniority_count, \n",
    "             'industry': industry_count, \n",
    "             'responsibility': responsibility_count, \n",
    "             'requirements': requirements_count}\n",
    "\n",
    "feats19 = feats20[1:].index\n",
    "\n",
    "for x in feats19:\n",
    "    print (x)\n",
    "    if x in company:\n",
    "        print ('appears in feature company')\n",
    "        company_count.append(x)\n",
    "    elif x in title:\n",
    "        print ('appears in feature title')\n",
    "        title_count.append(x)\n",
    "    elif x in address:\n",
    "        print ('appears in feature address')\n",
    "        address_count.append(x)\n",
    "    elif x in emp_type:\n",
    "        print ('appears in feature emp_type')\n",
    "        emp_type_count.append(x)\n",
    "    elif x in seniority:\n",
    "        print ('appears in feature seniority')\n",
    "        seniority_count.append(x)\n",
    "    elif x in industry:\n",
    "        print ('appears in feature industry')\n",
    "        industry_count.append(x)\n",
    "    elif x in responsibility:\n",
    "        print ('appears in feature responsibility')\n",
    "        responsibility_count.append(x)\n",
    "    elif x in requirements:\n",
    "        print ('appears in feature requirements')\n",
    "        requirements_count.append(x)\n",
    "    else:\n",
    "        print ('word not in list, how can that be?')\n",
    "    print ('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company 3\n",
      "title 4\n",
      "address 0\n",
      "emp_type 0\n",
      "seniority 0\n",
      "industry 0\n",
      "responsibility 11\n",
      "requirements 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in countdict.items():\n",
    "    #print value\n",
    "    print(key, len([item for item in value if item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "forest = RandomForestClassifier()\n",
    "cv = CountVectorizer(stop_words=stopwordslist, ngram_range=(1,2))\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify=y)\n",
    "forest.fit(X_train, y_train)\n",
    "print (forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOMIZED SEARCH  CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True, total=   1.8s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True, total=   1.9s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=40, bootstrap=True, total=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    2.6s remaining:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=   2.3s\n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=   1.7s\n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7391304347826086"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [20, 40, 60, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 1000, 1800]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 2, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "rf_random.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTHER THINGS I WILL NEED TO TRY\n",
    "\n",
    "1. SVM\n",
    "2. TFID VECTORIZOR\n",
    "3. FEATURE ENGINEERING\n",
    "4. BOOSTING TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "2. https://towardsdatascience.com/ensemble-methods-in-machine-learning-what-are-they-and-why-use-them-68ec3f9fef5f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
